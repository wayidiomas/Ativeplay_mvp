#!/usr/bin/env python3
"""
M3U Chunk Analyzer - Demonstra o agrupamento natural de s√©ries
Baseado no algoritmo usado pelo AtivePlay para processar M3U em chunks
"""
import re
from typing import List, Dict, Optional

# Regex para detectar SxxExx
SERIES_PATTERN = re.compile(r'S(\d{1,2})E(\d{1,2})', re.IGNORECASE)

def parse_extinf(line: str) -> Optional[Dict]:
    """Parseia linha #EXTINF"""
    if not line.startswith('#EXTINF:'):
        return None

    # Extrai tvg-name e group-title
    name_match = re.search(r'tvg-name="([^"]*)"', line)
    group_match = re.search(r'group-title="([^"]*)"', line)

    if not name_match:
        return None

    name = name_match.group(1)
    group = group_match.group(1) if group_match else ""

    # Detecta season/episode
    series_match = SERIES_PATTERN.search(name)
    if not series_match:
        return None

    season = int(series_match.group(1))
    episode = int(series_match.group(2))

    # Remove SxxExx do nome para obter nome base
    base_name = SERIES_PATTERN.sub('', name).strip()
    # Remove tags comuns
    base_name = re.sub(r'\[.*?\]', '', base_name).strip()
    base_name = re.sub(r'\(.*?\)', '', base_name).strip()

    return {
        'name': name,
        'base_name': base_name,
        'group': group,
        'season': season,
        'episode': episode
    }

def process_chunks(m3u_path: str, chunk_size: int = 100):
    """Processa M3U em chunks e mostra agrupamento natural"""

    print(f"Analisando arquivo M3U: {m3u_path}")
    print(f"Chunk size: {chunk_size} items\n")

    with open(m3u_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    chunk_num = 0
    i = 0

    while i < len(lines) and chunk_num < 2:  # Apenas 2 chunks para demonstra√ß√£o
        chunk_items = []
        chunk_start = i

        # Acumula items at√© atingir chunk_size
        while len(chunk_items) < chunk_size and i < len(lines):
            line = lines[i].strip()

            if line.startswith('#EXTINF'):
                item = parse_extinf(line)
                if item and i + 1 < len(lines):
                    url_line = lines[i + 1].strip()
                    if url_line.startswith('http'):
                        item['url'] = url_line
                        chunk_items.append(item)
                        i += 2
                        continue
            i += 1

        if not chunk_items:
            break

        # Analisa agrupamento na chunk
        print(f"\n{'='*80}")
        print(f"CHUNK #{chunk_num + 1} (Linhas {chunk_start}-{i})")
        print(f"Total items nesta chunk: {len(chunk_items)}")
        print(f"{'='*80}\n")

        # Agrupa por s√©rie base
        series_groups = {}
        for item in chunk_items:
            key = item['base_name']
            if key not in series_groups:
                series_groups[key] = []
            series_groups[key].append(item)

        # Mostra grupos com m√∫ltiplos epis√≥dios
        series_count = 0
        for series_name, episodes in sorted(series_groups.items(), key=lambda x: -len(x[1])):
            if len(episodes) > 1:  # Apenas s√©ries com m√∫ltiplos epis√≥dios
                series_count += 1
                print(f"üì∫ {series_name}")
                print(f"   Epis√≥dios: {len(episodes)}")

                seasons = sorted(set(ep['season'] for ep in episodes))
                print(f"   Temporadas: {seasons}")

                first_ep = episodes[0]
                last_ep = episodes[-1]
                print(f"   Range: S{first_ep['season']:02}E{first_ep['episode']:02} ‚Üí " +
                      f"S{last_ep['season']:02}E{last_ep['episode']:02}")
                print(f"   Grupo: {episodes[0]['group'][:60]}")

                # Mostra primeiros 5 epis√≥dios
                print(f"   Epis√≥dios sequenciais:")
                for ep in episodes[:5]:
                    print(f"     - S{ep['season']:02}E{ep['episode']:02}: {ep['name'][:60]}")
                if len(episodes) > 5:
                    print(f"     ... +{len(episodes) - 5} epis√≥dios")
                print()

        print(f"Total de s√©ries detectadas nesta chunk: {series_count}")
        print(f"Total de epis√≥dios de s√©ries: {sum(len(eps) for eps in series_groups.values() if len(eps) > 1)}")

        chunk_num += 1

if __name__ == '__main__':
    m3u_file = '/Users/lucassouza/Projects/Macbook/AtivePlay/m3u_example/playlist_199003005_plus.m3u'
    process_chunks(m3u_file, chunk_size=100)

    print("\n" + "="*80)
    print("‚úÖ Conclus√£o: S√©ries v√™m AGRUPADAS SEQUENCIALMENTE no arquivo M3U!")
    print("="*80)
    print("\nEsse padr√£o permite otimizar o processamento com RLE (Run-Length Encoding):")
    print("- Detectar runs consecutivos de epis√≥dios da mesma s√©rie")
    print("- Processar em bloco (1 normaliza√ß√£o + 1 hash + 1 DB op)")
    print("- Reduzir 90%+ das opera√ß√µes para s√©ries com muitos epis√≥dios")
