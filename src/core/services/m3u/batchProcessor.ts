/**
 * Batch Processor
 * Processa itens do streaming parser em lotes, mantendo UI responsiva
 * FASE 1: Adiciona series grouping hÃ­brido (hash-based durante streaming)
 * FASE 7.2: Adiciona criaÃ§Ã£o incremental de Series no DB
 */

import { db, type M3UItem, type Series } from '@core/db/schema';
import { ContentClassifier } from './classifier';
import { normalizeSeriesName, createSeriesKey, normalizeGroup, normalizeTitle, hashURL } from './utils';
import { getBatchConfig } from './deviceDetection'; // âœ… FASE 2: Device-adaptive config
import type {
  M3UParsedItem,
  M3UGroup,
  M3UPlaylist,
  PlaylistStats,
  ParserProgress,
  MediaKind,
} from './types';

export type ProgressCallback = (progress: ParserProgress) => void;

// âœ… FASE 7.1: Callback para navegaÃ§Ã£o antecipada (apÃ³s primeiros items)
export type EarlyReadyCallback = (stats: {
  itemsLoaded: number;
  liveCount: number;
  movieCount: number;
  seriesCount: number;
}) => void | Promise<void>;

const YIELD_INTERVAL = 0; // Yield para UI (setTimeout 0ms)
const EARLY_NAV_THRESHOLD = 500; // âœ… FASE 7.1: Navega apÃ³s 500 items carregados

// âœ… FASE 2: REMOVIDO - Agora usa config adaptativo
// const BATCH_SIZE = 100;
// const GC_INTERVAL = 10;

// Interface para tracking de sÃ©ries durante streaming
export interface SeriesGroup {
  seriesKey: string;      // Hash normalizado (ID Ãºnico)
  seriesName: string;     // Nome original da sÃ©rie
  itemIds: string[];      // IDs dos episÃ³dios
  seasons: Set<number>;   // Temporadas Ãºnicas
  episodeCount: number;   // Total de episÃ³dios
}

/**
 * Gera ID Ãºnico para um grupo
 */
function generateGroupId(name: string, mediaKind: MediaKind): string {
  const safeName = name.replace(/[^a-zA-Z0-9]/g, '_').toLowerCase();
  return `group_${safeName}_${mediaKind}`;
}

/**
 * Processa itens do stream em lotes e insere no banco
 * FASE 1: Adiciona series grouping incremental (hash-based)
 * FASE 7.1: Adiciona early navigation callback
 *
 * @param generator AsyncGenerator que produz itens parseados
 * @param playlistId ID da playlist
 * @param onProgress Callback de progresso
 * @param onEarlyReady Callback disparado ao atingir threshold (500 items)
 * @returns Playlist completa com stats, grupos e seriesGroups
 */
export async function processBatches(
  generator: AsyncGenerator<M3UParsedItem>,
  playlistId: string,
  onProgress?: ProgressCallback,
  onEarlyReady?: EarlyReadyCallback
): Promise<Omit<M3UPlaylist, 'url'> & { seriesGroups: SeriesGroup[] }> {
  // âœ… FASE 2: Config adaptativo baseado no device
  const config = getBatchConfig();
  const BATCH_SIZE = config.itemBatchSize;
  const GC_INTERVAL = config.gcInterval;

  const groupsMap = new Map<string, M3UGroup>();
  const seriesGroupsMap = new Map<string, SeriesGroup>(); // âœ… FASE 1: Series tracking
  const stats: PlaylistStats = {
    totalItems: 0,
    liveCount: 0,
    movieCount: 0,
    seriesCount: 0,
    unknownCount: 0,
    groupCount: 0,
  };

  // âœ… FASE 7.2: Cache e batch updates para Series incrementais
  const seriesDbCache = new Map<string, Series>(); // seriesKey -> Series (evita DB reads)
  const seriesToUpdate = new Map<string, Partial<Series>>(); // Acumula updates para batch

  let batch: M3UParsedItem[] = [];
  let totalProcessed = 0;
  let batchCount = 0; // âœ… FASE 1: Para GC interval
  let earlyReadyFired = false; // âœ… FASE 7.1: Controla disparo Ãºnico do early callback

  try {
    for await (const item of generator) {
      batch.push(item);
      // NOTE: NÃ£o acumulamos items em memÃ³ria para economizar RAM
      // Os items sÃ£o inseridos no DB progressivamente

      // Update stats
      stats.totalItems++;
      switch (item.mediaKind) {
        case 'live':
          stats.liveCount++;
          break;
        case 'movie':
          stats.movieCount++;
          break;
        case 'series':
          stats.seriesCount++;
          break;
        default:
          stats.unknownCount++;
      }

      // Update groups map
      const groupId = generateGroupId(item.group, item.mediaKind);
      const existingGroup = groupsMap.get(groupId);
      if (existingGroup) {
        existingGroup.itemCount++;
      } else {
        groupsMap.set(groupId, {
          id: groupId,
          name: item.group,
          mediaKind: item.mediaKind,
          itemCount: 1,
          logo: item.logo,
        });
      }

      // âœ… NOVO: Series grouping incremental (hash-based)
      if (item.mediaKind === 'series' && item.parsedTitle?.season) {
        const seriesInfo = ContentClassifier.extractSeriesInfo(item.name);

        if (seriesInfo) {
          // Normaliza nome (remove tags, anos, qualidade, etc)
          const normalized = normalizeSeriesName(seriesInfo.seriesName);
          const seriesKey = createSeriesKey(normalized);

          if (!seriesGroupsMap.has(seriesKey)) {
            seriesGroupsMap.set(seriesKey, {
              seriesKey,
              seriesName: seriesInfo.seriesName,
              itemIds: [],
              seasons: new Set(),
              episodeCount: 0,
            });
          }

          const group = seriesGroupsMap.get(seriesKey)!;
          group.itemIds.push(item.id);
          group.seasons.add(seriesInfo.season);
          group.episodeCount++;

          // âœ… FASE 7.2: CriaÃ§Ã£o/atualizaÃ§Ã£o incremental de Series no DB
          const seriesDbId = `${playlistId}_${seriesKey}`;

          // Verifica cache antes de DB
          let existingSeries = seriesDbCache.get(seriesKey);

          if (!existingSeries) {
            // Cache miss: verifica no DB (apenas primeira vez)
            existingSeries = await db.series.get(seriesDbId) || undefined;

            if (!existingSeries) {
              // âœ… NOVA SÃ‰RIE: Cria no DB imediatamente
              const newSeries: Series = {
                id: seriesDbId,
                playlistId,
                name: seriesInfo.seriesName,
                logo: item.logo || '',
                group: item.group,
                totalEpisodes: 1,
                totalSeasons: 1,
                firstSeason: seriesInfo.season,
                lastSeason: seriesInfo.season,
                firstEpisode: seriesInfo.episode,
                lastEpisode: seriesInfo.episode,
                year: item.parsedTitle.year,
                quality: item.parsedTitle.quality,
                createdAt: Date.now(),
              };

              await db.series.add(newSeries);
              seriesDbCache.set(seriesKey, newSeries);

              console.log(`[Series] âœ… NOVA: ${seriesInfo.seriesName} (S${seriesInfo.season}E${seriesInfo.episode})`);
            } else {
              // SÃ©rie existente - adiciona ao cache
              seriesDbCache.set(seriesKey, existingSeries);
            }
          }

          // âœ… SÃ‰RIE EXISTENTE: Acumula updates para batch
          if (existingSeries) {
            const cached = seriesDbCache.get(seriesKey)!;
            const updates: Partial<Series> = {
              totalEpisodes: cached.totalEpisodes + 1,
              totalSeasons: Math.max(cached.totalSeasons, seriesInfo.season),
              lastSeason: Math.max(cached.lastSeason || 0, seriesInfo.season),
              lastEpisode: Math.max(cached.lastEpisode || 0, seriesInfo.episode),
              firstSeason: Math.min(cached.firstSeason || Infinity, seriesInfo.season),
              firstEpisode: Math.min(cached.firstEpisode || Infinity, seriesInfo.episode),
            };

            // Atualiza cache local
            Object.assign(cached, updates);

            // Acumula para batch update
            seriesToUpdate.set(seriesDbId, updates);
          }
        }
      }

      // Processa batch quando atingir tamanho limite
      if (batch.length >= BATCH_SIZE) {
        // Prepara itens para inserÃ§Ã£o no DB
        const dbItems: M3UItem[] = batch.map((item) => {
          // âœ… NOVO: Extrai seriesId para items de sÃ©ries
          const seriesInfo = ContentClassifier.extractSeriesInfo(item.name);
          let seriesId: string | undefined;
          let seasonNumber: number | undefined;
          let episodeNumber: number | undefined;

          if (seriesInfo && item.mediaKind === 'series') {
            const normalized = normalizeSeriesName(seriesInfo.seriesName);
            seriesId = createSeriesKey(normalized);
            seasonNumber = seriesInfo.season;
            episodeNumber = seriesInfo.episode;
          }

          return {
            id: `${playlistId}_${item.id}`,
            playlistId,
            name: item.name,
            url: item.url,
            logo: item.logo,
            group: item.group,
            mediaKind: item.mediaKind,
            title: item.parsedTitle.title,
            titleNormalized: normalizeTitle(item.parsedTitle.title || item.name),  // âœ… FASE OTIMIZAÃ‡ÃƒO
            groupNormalized: normalizeGroup(item.group),                          // âœ… FASE OTIMIZAÃ‡ÃƒO
            urlHash: hashURL(item.url),                                           // âœ… FASE OTIMIZAÃ‡ÃƒO
            year: item.parsedTitle.year,
            season: item.parsedTitle.season,
            episode: item.parsedTitle.episode,
            quality: item.parsedTitle.quality,
            epgId: item.epgId,
            seriesId,        // âœ… NOVO
            seasonNumber,    // âœ… NOVO
            episodeNumber,   // âœ… NOVO
            createdAt: Date.now(),
          };
        });

        // Insere no DB com fallback triplo
        try {
          await db.items.bulkAdd(dbItems);
        } catch (error) {
          console.warn('[BatchProcessor] bulkAdd falhou, tentando bulkPut (upsert):', (error as Error).message);

          try {
            // Fallback: upsert (substitui duplicatas)
            await db.items.bulkPut(dbItems);
            console.log('[BatchProcessor] âœ“ Batch salvo via bulkPut (upsert)');
          } catch (putError) {
            console.error('[BatchProcessor] âŒ ERRO CRÃTICO: batch pode ser perdido', {
              batchSize: dbItems.length,
              error: (putError as Error).message,
              firstItem: dbItems[0]?.id,
              lastItem: dbItems[dbItems.length - 1]?.id,
            });

            // âš ï¸ Ãšltima tentativa: insere item por item
            let savedCount = 0;
            for (const item of dbItems) {
              try {
                await db.items.put(item);
                savedCount++;
              } catch {
                console.error('[BatchProcessor] Item rejeitado:', item.id);
              }
            }

            console.warn(`[BatchProcessor] Salvou ${savedCount}/${dbItems.length} items individualmente`);
          }
        }

        // âœ… FASE 7.2: Flush series updates a cada batch
        if (seriesToUpdate.size > 0) {
          console.log(`[Series] ðŸ“ Atualizando ${seriesToUpdate.size} sÃ©ries...`);

          for (const [id, updates] of seriesToUpdate.entries()) {
            try {
              await db.series.update(id, updates);
            } catch (err) {
              console.error(`[Series] Erro ao atualizar ${id}:`, err);
              // Continua com prÃ³ximas series mesmo se uma falhar
            }
          }

          seriesToUpdate.clear();
        }

        totalProcessed += batch.length;
        batchCount++; // âœ… NOVO: Incrementa contador de batches

        // âœ… FASE 7.1: Dispara early ready callback apÃ³s threshold
        if (!earlyReadyFired && totalProcessed >= EARLY_NAV_THRESHOLD && onEarlyReady) {
          earlyReadyFired = true;
          console.log(`[BatchProcessor] âœ… EARLY READY! ${totalProcessed} items carregados, disparando callback...`);

          try {
            await onEarlyReady({
              itemsLoaded: totalProcessed,
              liveCount: stats.liveCount,
              movieCount: stats.movieCount,
              seriesCount: stats.seriesCount,
            });
          } catch (err) {
            console.error('[BatchProcessor] Erro no onEarlyReady callback:', err);
            // NÃ£o interrompe o parsing se callback falhar
          }
        }

        // Report progress (nÃ£o sabemos total ainda no streaming)
        onProgress?.({
          phase: 'indexing',
          current: totalProcessed,
          total: totalProcessed, // Total estimado = processado atÃ© agora
          percentage: 0, // Indeterminado em streaming
          message: `Processando... ${totalProcessed} itens`,
        });

        // Limpa batch
        batch = [];

        // âœ… NOVO: Force GC a cada N batches para liberar memÃ³ria
        if (batchCount % GC_INTERVAL === 0) {
          if (globalThis.gc) {
            globalThis.gc();
            console.log(`[BatchProcessor] GC forÃ§ado apÃ³s ${batchCount} batches`);
          }
          // Yield extra para dar tempo ao GC
          await new Promise((resolve) => setTimeout(resolve, 10));
        } else {
          // Yield normal para UI atualizar (evita bloquear thread)
          await new Promise((resolve) => setTimeout(resolve, YIELD_INTERVAL));
        }
      }
    }

    // Processa Ãºltimos itens do batch (se houver)
    if (batch.length > 0) {
      const dbItems: M3UItem[] = batch.map((item) => {
        // âœ… NOVO: Extrai seriesId para items de sÃ©ries (mesmo cÃ³digo do batch principal)
        const seriesInfo = ContentClassifier.extractSeriesInfo(item.name);
        let seriesId: string | undefined;
        let seasonNumber: number | undefined;
        let episodeNumber: number | undefined;

        if (seriesInfo && item.mediaKind === 'series') {
          const normalized = normalizeSeriesName(seriesInfo.seriesName);
          seriesId = createSeriesKey(normalized);
          seasonNumber = seriesInfo.season;
          episodeNumber = seriesInfo.episode;
        }

        return {
          id: `${playlistId}_${item.id}`,
          playlistId,
          name: item.name,
          url: item.url,
          logo: item.logo,
          group: item.group,
          mediaKind: item.mediaKind,
          title: item.parsedTitle.title,
          year: item.parsedTitle.year,
          season: item.parsedTitle.season,
          episode: item.parsedTitle.episode,
          quality: item.parsedTitle.quality,
          epgId: item.epgId,
          seriesId,        // âœ… NOVO
          seasonNumber,    // âœ… NOVO
          episodeNumber,   // âœ… NOVO
          createdAt: Date.now(),
        };
      });

      try {
        await db.items.bulkAdd(dbItems);
      } catch (error) {
        console.warn('[BatchProcessor] bulkAdd falhou no Ãºltimo batch, usando bulkPut:', (error as Error).message);

        try {
          await db.items.bulkPut(dbItems);
          console.log('[BatchProcessor] âœ“ Ãšltimo batch salvo via bulkPut (upsert)');
        } catch (putError) {
          console.error('[BatchProcessor] âŒ ERRO no Ãºltimo batch', {
            batchSize: dbItems.length,
            error: (putError as Error).message,
          });

          // Ãšltima tentativa: item por item
          let savedCount = 0;
          for (const item of dbItems) {
            try {
              await db.items.put(item);
              savedCount++;
            } catch {
              console.error('[BatchProcessor] Item rejeitado:', item.id);
            }
          }

          console.warn(`[BatchProcessor] Ãšltimo batch: ${savedCount}/${dbItems.length} salvos`);
        }
      }

      totalProcessed += batch.length;

      // âœ… FASE 7.2: Flush final de series updates (Ãºltimo batch)
      if (seriesToUpdate.size > 0) {
        console.log(`[Series] ðŸ“ Atualizando ${seriesToUpdate.size} sÃ©ries (Ãºltimo batch)...`);

        for (const [id, updates] of seriesToUpdate.entries()) {
          try {
            await db.series.update(id, updates);
          } catch (err) {
            console.error(`[Series] Erro ao atualizar ${id}:`, err);
          }
        }

        seriesToUpdate.clear();
      }
    }

    // Finaliza grupos
    const groups = Array.from(groupsMap.values());
    stats.groupCount = groups.length;

    // Salva grupos no DB
    const dbGroups = groups.map((group) => ({
      id: `${playlistId}_${group.id}`,
      playlistId,
      name: group.name,
      mediaKind: group.mediaKind,
      itemCount: group.itemCount,
      logo: group.logo,
      createdAt: Date.now(),
    }));

    if (dbGroups.length > 0) {
      try {
        await db.groups.bulkAdd(dbGroups);
      } catch (error) {
        console.warn('[BatchProcessor] bulkAdd de grupos falhou, usando bulkPut:', (error as Error).message);

        try {
          await db.groups.bulkPut(dbGroups);
          console.log('[BatchProcessor] âœ“ Grupos salvos via bulkPut (upsert)');
        } catch (putError) {
          console.error('[BatchProcessor] Erro ao salvar grupos:', (putError as Error).message);
          // Groups sÃ£o menos crÃ­ticos, pode continuar
        }
      }
    }

    // Progress final
    onProgress?.({
      phase: 'complete',
      current: totalProcessed,
      total: totalProcessed,
      percentage: 100,
      message: `ConcluÃ­do! ${stats.totalItems} itens processados.`,
    });

    // âœ… NOVO: Converte Set para array no seriesGroups
    const seriesGroupsArray: SeriesGroup[] = Array.from(seriesGroupsMap.values()).map(group => ({
      ...group,
      seasons: group.seasons, // MantÃ©m como Set por enquanto (serÃ¡ usado no fuzzy merge)
    }));

    // DEBUG: Log stats
    console.log('[BatchProcessor] ===== STATS FINAIS =====');
    console.log(`[BatchProcessor] Total Items: ${stats.totalItems}`);
    console.log(`[BatchProcessor] Movies: ${stats.movieCount}`);
    console.log(`[BatchProcessor] Series: ${stats.seriesCount}`);
    console.log(`[BatchProcessor] Live: ${stats.liveCount}`);
    console.log(`[BatchProcessor] Unknown: ${stats.unknownCount}`);
    console.log(`[BatchProcessor] Groups: ${stats.groupCount}`);
    console.log(`[BatchProcessor] Series Groups: ${seriesGroupsArray.length}`); // âœ… NOVO

    return {
      items: [], // Items jÃ¡ foram inseridos no DB - nÃ£o retornamos para economizar memÃ³ria
      groups,
      stats,
      seriesGroups: seriesGroupsArray, // âœ… NOVO: Retorna series groups para fuzzy merge
    };
  } catch (error) {
    onProgress?.({
      phase: 'error',
      current: totalProcessed,
      total: totalProcessed,
      percentage: 0,
      message: `Erro no processamento: ${(error as Error).message}`,
    });
    throw error;
  }
}

export default { processBatches };
